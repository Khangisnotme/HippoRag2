PPDX 

```bash
(.venv) PS D:\GIT\Repython .\PPDX_run_excel_non_rank_retrieval_evaluator.pyt\src\system\eval\retrieval>
Reading Excel file: D:\GIT\ResearchProject_Memory-AugmentedAIAgents_GraduationProject\src\system\eval\input\main_vimqa_dev_300lines.xlsx
Processing data...
Total unique documents in corpus: 663
Running evaluation...
Adding evaluation metrics to dataframe...
Saving results to: D:\GIT\ResearchProject_Memory-AugmentedAIAgents_GraduationProject\src\system\eval\retrieval\outputs\main_vimqa_dev_300lines_PPDX_non_rank_retrieval_evaluator.xlsx  

Evaluation Summary:
=== B√ÅO C√ÅO ƒê√ÅNH GI√Å NON-RANK METRICS ===

üìö TH√îNG TIN CORPUS:
  ‚Ä¢ T·ªïng s·ªë t√†i li·ªáu unique: 663
  ‚Ä¢ C√°ch t√≠nh: L·∫•y union c·ªßa t·∫•t c·∫£ document IDs t·ª´ retrieved_docs v√† supporting_facts

üìä PH∆Ø∆†NG PH√ÅP T√çNH TRUNG B√åNH:
  ‚Ä¢ MACRO-AVERAGED: T√≠nh trung b√¨nh ƒë∆°n gi·∫£n c·ªßa c√°c metrics t·ª´ t·ª´ng truy v·∫•n.
    - ∆Øu ƒëi·ªÉm: M·ªói truy v·∫•n c√≥ tr·ªçng s·ªë b·∫±ng nhau
    - Ph√π h·ª£p khi: C√°c truy v·∫•n c√≥ t·∫ßm quan tr·ªçng nh∆∞ nhau   
    - V√≠ d·ª•: C√≥ 3 truy v·∫•n v·ªõi Precision l·∫ßn l∆∞·ª£t l√† 0.8, 0.6, 0.4
      MACRO Precision = (0.8 + 0.6 + 0.4) / 3 = 0.6

  ‚Ä¢ MICRO-AVERAGED: T√≠nh metrics tr√™n t·ªïng s·ªë TP, FP, FN c·ªßa t·∫•t c·∫£ truy v·∫•n.
    - ∆Øu ƒëi·ªÉm: Ph·∫£n √°nh hi·ªáu su·∫•t t·ªïng th·ªÉ tr√™n to√†n b·ªô d·ªØ li·ªáu
    - Ph√π h·ª£p khi: C·∫ßn ƒë√°nh gi√° hi·ªáu su·∫•t tr√™n t·∫≠p d·ªØ li·ªáu l·ªõn
    - V√≠ d·ª•:
      + Truy v·∫•n 1: TP=2, FP=1, FN=1
      + Truy v·∫•n 2: TP=3, FP=2, FN=0
      + Truy v·∫•n 3: TP=1, FP=1, FN=2
      T·ªïng: TP=6, FP=4, FN=3
      MICRO Precision = 6/(6+4) = 0.6

  S·ª± kh√°c bi·ªát ch√≠nh:
  - MACRO: M·ªói truy v·∫•n c√≥ tr·ªçng s·ªë b·∫±ng nhau, kh√¥ng quan t√¢m s·ªë l∆∞·ª£ng t√†i li·ªáu
  - MICRO: C√°c truy v·∫•n c√≥ nhi·ªÅu t√†i li·ªáu s·∫Ω c√≥ ·∫£nh h∆∞·ªüng l·ªõn h∆°n ƒë·∫øn k·∫øt qu·∫£ cu·ªëi c√πng

üìä MACRO-AVERAGED METRICS:
  ‚Ä¢ Precision: 0.474
  ‚Ä¢ Recall@K: 0.732
  ‚Ä¢ F1-Score: 0.538
  ‚Ä¢ Hit Rate@K: 0.907
  ‚Ä¢ Accuracy: 0.997

üìà MICRO-AVERAGED METRICS:
  ‚Ä¢ Precision: 0.417
  ‚Ä¢ Recall@K: 0.710
  ‚Ä¢ F1-Score: 0.526

üéØ ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG:
  ‚Ä¢ Hit Rate: XU·∫§T S·∫ÆC (‚â•80% truy v·∫•n c√≥ k·∫øt qu·∫£ li√™n quan)  
  ‚Ä¢ Precision: TH·∫§P (nhi·ªÅu k·∫øt qu·∫£ kh√¥ng li√™n quan)
  ‚Ä¢ Recall: CAO (t√¨m ƒë∆∞·ª£c nhi·ªÅu t√†i li·ªáu li√™n quan)
```


