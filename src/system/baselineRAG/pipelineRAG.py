"""
RAG Pipeline - K·∫øt h·ª£p retrieval v√† generation ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
"""

from typing import List, Dict, Any, Optional
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv
import os
import sys
from pathlib import Path

# Setup paths
current_file = Path(__file__)

sys.path.append(str(current_file.parent.parent))

# Import c√°c module ƒë√£ c√≥
from layers._04_retrieval.retriever import DocumentRetriever
from layers._05_generation.generator import AnswerGenerator

# Load environment variables
load_dotenv()

# Default system prompts
DEFAULT_SYSTEM_PROMPT = """You are a helpful assistant that answers questions based on the given context. 
If you don't know the answer, say you don't know. 
Use only the information from the context to answer. 
Keep your answers clear and simple."""

VIETNAMESE_SYSTEM_PROMPT = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch, tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p. 
N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i b·∫°n kh√¥ng bi·∫øt. 
Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ context ƒë·ªÉ tr·∫£ l·ªùi. 
Gi·ªØ c√¢u tr·∫£ l·ªùi r√µ r√†ng v√† ƒë∆°n gi·∫£n."""

class RAGPipeline:
    """
    Pipeline RAG ho√†n ch·ªânh: Input -> Retrieval -> Generation -> Output
    """
    
    def __init__(
        self,
        # Retriever parameters
        retriever_type: str = "vector",
        vector_store_type: str = "qdrant",
        documents: Optional[List[Document]] = None,
        embeddings_model = None,
        hybrid_weights: List[float] = [0.5, 0.5],
        k: int = 5,
        
        # Vector store parameters
        qdrant_url: Optional[str] = None,
        qdrant_api_key: Optional[str] = None,
        collection_name: str = "VIMQA_dev",
        
        # Generator parameters
        generator_model: str = "gpt-4o-mini",
        temperature: float = 0,
        max_tokens: int = 4096,
        system_prompt: Optional[str] = None
    ):
        """
        Kh·ªüi t·∫°o RAG Pipeline
        
        Args:
            retriever_type: Lo·∫°i retriever ("vector", "bm25", "hybrid", "compression")
            vector_store_type: Lo·∫°i vector store ("qdrant")
            documents: List documents cho BM25 v√† hybrid
            embeddings_model: Model embedding
            hybrid_weights: Tr·ªçng s·ªë cho hybrid search [vector_weight, bm25_weight]
            k: S·ªë l∆∞·ª£ng documents tr·∫£ v·ªÅ
            qdrant_url: URL Qdrant server
            qdrant_api_key: API key Qdrant
            collection_name: T√™n collection
            generator_model: Model OpenAI ho·∫∑c Hugging Face
            temperature: ƒê·ªô s√°ng t·∫°o c·ªßa model
            max_tokens: S·ªë token t·ªëi ƒëa
            system_prompt: System prompt t√πy ch·ªânh
        """
        
        # Kh·ªüi t·∫°o embeddings model n·∫øu ch∆∞a c√≥
        if embeddings_model is None:
            self.embeddings_model = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
            )
        else:
            self.embeddings_model = embeddings_model
        
        # Store documents for later use
        self.documents = documents or []
        
        # Kh·ªüi t·∫°o Document Retriever
        self.retriever = DocumentRetriever(
            retriever_type=retriever_type,
            vector_store_type=vector_store_type,
            documents=self.documents,
            embeddings_model=self.embeddings_model,
            hybrid_weights=hybrid_weights,
            k=k,
            qdrant_url=qdrant_url or os.getenv("QDRANT_URL"),
            qdrant_api_key=qdrant_api_key or os.getenv("QDRANT_API_KEY"),
            collection_name=collection_name
        )
        
        # Determine if using Hugging Face model
        self.is_hf_model = any(provider in generator_model for provider in 
                              ["Qwen/", "AITeamVN/", "microsoft/", "huggingface/"])
        
        # Determine if Vietnamese-focused model
        self.is_vietnamese = any(keyword in generator_model.lower() for keyword in 
                               ["vi-qwen", "vietnamese", "vi_", "vn_"]) or "Qwen" in generator_model
        
        # Set appropriate system prompt
        if system_prompt is None:
            self.system_prompt = VIETNAMESE_SYSTEM_PROMPT if self.is_vietnamese else DEFAULT_SYSTEM_PROMPT
        else:
            self.system_prompt = system_prompt
        
        # Kh·ªüi t·∫°o Answer Generator
        self.generator = AnswerGenerator(
            model_name=generator_model,
            temperature=temperature,
            max_tokens=max_tokens,
            system_prompt=self.system_prompt
        )
        
        # Fix: Add documents to vector store if using vector retriever
        if self.documents and retriever_type in ["vector", "hybrid"]:
            self._ensure_documents_indexed()
        
        print(f"RAG Pipeline initialized with:")
        print(f"  - Retriever: {retriever_type}")
        print(f"  - Vector Store: {vector_store_type}")
        print(f"  - Generator: {generator_model}")
        print(f"  - Model Type: {'Hugging Face' if self.is_hf_model else 'OpenAI'}")
        print(f"  - Language: {'Vietnamese' if self.is_vietnamese else 'English'}")
        print(f"  - K documents: {k}")
        print(f"  - Documents loaded: {len(self.documents)}")
    
    def _ensure_documents_indexed(self):
        """
        ƒê·∫£m b·∫£o documents ƒë√£ ƒë∆∞·ª£c index v√†o vector store
        """
        try:
            if hasattr(self.retriever, 'vector_store') and self.retriever.vector_store:
                # Try to get collection info
                try:
                    collection_info = self.retriever.vector_store.get_collection_info()
                    if collection_info and collection_info.get('vectors_count', 0) == 0:
                        print(f"üìù Indexing {len(self.documents)} documents to vector store...")
                        self.retriever.vector_store.add_documents(self.documents)
                        print(f"‚úÖ Documents indexed successfully")
                    else:
                        print(f"üìö Vector store already contains documents")
                except:
                    # If can't get collection info, try to add documents anyway
                    print(f"üìù Attempting to index {len(self.documents)} documents...")
                    if self.documents:
                        self.retriever.vector_store.add_documents(self.documents)
                        print(f"‚úÖ Documents added to vector store")
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not verify/index documents: {e}")
            print(f"    This might be okay if documents are already indexed")
    
    def query(
        self, 
        question: str,
        return_sources: bool = True,
        return_documents: bool = False
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω c√¢u h·ªèi qua pipeline RAG ho√†n ch·ªânh
        
        Args:
            question: C√¢u h·ªèi c·ªßa user
            return_sources: C√≥ tr·∫£ v·ªÅ sources kh√¥ng
            return_documents: C√≥ tr·∫£ v·ªÅ raw documents kh√¥ng
            
        Returns:
            Dictionary ch·ª©a answer v√† th√¥ng tin b·ªï sung
        """
        
        print(f"\nüîç Retrieving documents for: '{question}'")
        
        # B∆∞·ªõc 1: Retrieve documents
        try:
            documents = self.retriever.retrieve_documents(question)
            print(f"‚úÖ Found {len(documents)} relevant documents")
            
            # Debug: Print document contents if found
            if len(documents) > 0:
                print("üìÑ Retrieved documents preview:")
                for i, doc in enumerate(documents[:2]):  # Show first 2 docs
                    content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                    print(f"   {i+1}. {content_preview}")
            else:
                print("‚ö†Ô∏è  No documents found, trying fallback...")
                # Fallback: use original documents if retrieval fails
                if self.documents:
                    documents = self.documents[:self.retriever.k]
                    print(f"üìö Using fallback documents: {len(documents)}")
                    
        except Exception as e:
            print(f"‚ùå Retrieval failed: {e}")
            # Fallback to original documents
            if self.documents:
                documents = self.documents[:self.retriever.k]
                print(f"üìö Using fallback documents: {len(documents)}")
            else:
                return {
                    "question": question,
                    "answer": "Xin l·ªói, kh√¥ng th·ªÉ t√¨m ki·∫øm t√†i li·ªáu li√™n quan.",
                    "error": str(e),
                    "num_documents_used": 0
                }
        
        # B∆∞·ªõc 2: Generate answer
        print(f"ü§ñ Generating answer...")
        try:
            if return_sources:
                result = self.generator.generate_answer_with_sources(question, documents)
                answer = result["answer"]
                sources = result["sources"]
            else:
                answer = self.generator.generate_answer(question, documents)
                sources = []
                
            print(f"‚úÖ Answer generated successfully")
            
        except Exception as e:
            print(f"‚ùå Generation failed: {e}")
            print(f"    Error details: {type(e).__name__}: {str(e)}")
            return {
                "question": question,
                "answer": "Xin l·ªói, kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi.",
                "error": str(e),
                "num_documents_used": len(documents) if 'documents' in locals() else 0
            }
        
        # Prepare result
        result = {
            "question": question,
            "answer": answer,
            "num_documents_used": len(documents)
        }
        
        if return_sources:
            result["sources"] = sources
            
        if return_documents:
            result["documents"] = [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in documents
            ]
        
        return result
    
    def batch_query(self, questions: List[str]) -> List[Dict[str, Any]]:
        """
        X·ª≠ l√Ω nhi·ªÅu c√¢u h·ªèi c√πng l√∫c
        
        Args:
            questions: List c√°c c√¢u h·ªèi
            
        Returns:
            List c√°c k·∫øt qu·∫£
        """
        results = []
        for i, question in enumerate(questions, 1):
            print(f"\nüìù Processing question {i}/{len(questions)}")
            result = self.query(question)
            results.append(result)
            
        return results
    
    def add_documents(self, new_documents: List[Document]):
        """
        Th√™m documents m·ªõi v√†o h·ªá th·ªëng
        
        Args:
            new_documents: List documents m·ªõi
        """
        try:
            # Add to local storage
            self.documents.extend(new_documents)
            
            if hasattr(self.retriever, 'vector_store') and self.retriever.vector_store:
                # Th√™m v√†o vector store
                self.retriever.vector_store.add_documents(new_documents)
                print(f"‚úÖ Added {len(new_documents)} documents to vector store")
                
            # C·∫≠p nh·∫≠t documents cho BM25 n·∫øu c·∫ßn
            if hasattr(self.retriever, 'documents') and self.retriever.documents is not None:
                self.retriever.documents.extend(new_documents)
                # Reinitialize BM25 retriever if needed
                if hasattr(self.retriever.retriever, 'bm25_retriever'):
                    self.retriever._initialize_retriever()
                print(f"‚úÖ Updated BM25 index with {len(new_documents)} new documents")
                
        except Exception as e:
            print(f"‚ùå Failed to add documents: {e}")
    
    def get_system_info(self) -> Dict[str, Any]:
        """
        L·∫•y th√¥ng tin v·ªÅ h·ªá th·ªëng RAG
        """
        return {
            "retriever_type": self.retriever.retriever_type,
            "vector_store_type": self.retriever.vector_store_type,
            "generator_model": self.generator.model_name,
            "k_documents": self.retriever.k,
            "temperature": self.generator.temperature,
            "collection_name": getattr(self.retriever.vector_store, 'collection_name', 'N/A'),
            "total_documents": len(self.documents)
        }

def create_rag_pipeline(
    documents: Optional[List[Document]] = None,
    retriever_type: str = "bm25",  # Changed default to BM25 for reliability
    generator_model: str = "gpt-4o-mini"
) -> RAGPipeline:
    """
    Factory function ƒë·ªÉ t·∫°o RAG pipeline ƒë∆°n gi·∫£n
    
    Args:
        documents: Documents ƒë·ªÉ index
        retriever_type: Lo·∫°i retriever
        generator_model: Model generator
        
    Returns:
        RAGPipeline instance
    """
    return RAGPipeline(
        retriever_type=retriever_type,
        documents=documents,
        generator_model=generator_model
    )

if __name__ == "__main__":
    """
    Demo v√† test RAG Pipeline
    """
    from langchain_core.documents import Document
    
    # T·∫°o sample documents
    sample_docs = [
        Document(
            page_content="RAG (Retrieval-Augmented Generation) l√† m·ªôt k·ªπ thu·∫≠t k·∫øt h·ª£p vi·ªác t√¨m ki·∫øm th√¥ng tin li√™n quan v·ªõi vi·ªác t·∫°o sinh ng√¥n ng·ªØ. RAG gi√∫p c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn.",
            metadata={"source": "rag_intro.txt", "doc_id": "RAG_1", "title": "Gi·ªõi thi·ªáu RAG", "excel_row": 1}
        ),
        Document(
            page_content="Vector search s·ª≠ d·ª•ng embeddings ƒë·ªÉ t√¨m ki·∫øm t√†i li·ªáu t∆∞∆°ng t·ª± v·ªÅ m·∫∑t ng·ªØ nghƒ©a. N√≥ hi·ªáu qu·∫£ h∆°n keyword search trong nhi·ªÅu tr∆∞·ªùng h·ª£p.",
            metadata={"source": "vector_search.txt", "doc_id": "VEC_1", "title": "Vector Search", "excel_row": 2}
        ),
        Document(
            page_content="OpenAI GPT-4 l√† m·ªôt m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn c√≥ kh·∫£ nƒÉng hi·ªÉu v√† t·∫°o sinh vƒÉn b·∫£n m·ªôt c√°ch t·ª± nhi√™n. N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu ·ª©ng d·ª•ng AI.",
            metadata={"source": "gpt4_info.txt", "doc_id": "GPT4_1", "title": "GPT-4", "excel_row": 3}
        ),
        Document(
            page_content="Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn trong AI v√† machine learning. C√°c th∆∞ vi·ªán nh∆∞ LangChain gi√∫p x√¢y d·ª±ng ·ª©ng d·ª•ng AI d·ªÖ d√†ng h∆°n.",
            metadata={"source": "python_ai.txt", "doc_id": "PY_1", "title": "Python & AI", "excel_row": 4}
        )
    ]
    
    print("üöÄ Testing RAG Pipeline...")
    
    # Test 1: BM25 retriever (more reliable for testing)
    print("\n" + "="*50)
    print("TEST 1: BM25 Retriever + GPT-4o-mini")
    print("="*50)
    try:
        rag = RAGPipeline(
            retriever_type="bm25",
            documents=sample_docs,
            k=3
        )
        
        # Test single query
        result = rag.query("RAG l√† g√¨?")
        print(f"\nüìã Question: {result['question']}")
        print(f"üí° Answer: {result['answer']}")
        print(f"üìö Sources: {result.get('sources', [])}")
        print(f"üìÑ Documents used: {result['num_documents_used']}")
        
    except Exception as e:
        print(f"‚ùå BM25 test failed: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 2: Vector retriever
    print("\n" + "="*50)
    print("TEST 2: Vector Retriever")
    print("="*50)
    try:
        rag_vector = RAGPipeline(
            retriever_type="vector",
            documents=sample_docs,
            k=2,
            collection_name="VIMQA_dev"  # Use unique collection name
        )
        
        result = rag_vector.query("Vector search ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?")
        print(f"\nüìã Question: {result['question']}")
        print(f"üí° Answer: {result['answer']}")
        print(f"üìö Sources: {result.get('sources', [])}")
        
    except Exception as e:
        print(f"‚ùå Vector test failed: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 3: Batch queries (only if BM25 test passed)
    print("\n" + "="*50)
    print("TEST 3: Batch Queries")
    print("="*50)
    try:
        if 'rag' in locals():
            questions = [
                "Python c√≥ ∆∞u ƒëi·ªÉm g√¨ trong AI?",
                "GPT-4 l√† g√¨?"
            ]
            
            results = rag.batch_query(questions)
            for i, result in enumerate(results, 1):
                print(f"\n{i}. {result['question']}")
                if 'error' not in result:
                    print(f"   Answer: {result['answer'][:100]}...")
                else:
                    print(f"   Error: {result['error']}")
                    
    except Exception as e:
        print(f"‚ùå Batch test failed: {e}")
    
    # Test 4: System info
    print("\n" + "="*50)
    print("TEST 4: System Information")
    print("="*50)
    try:
        if 'rag' in locals():
            info = rag.get_system_info()
            print("üîß System Configuration:")
            for key, value in info.items():
                print(f"   {key}: {value}")
                
    except Exception as e:
        print(f"‚ùå System info test failed: {e}")
    
    # Test 5: Simple functional test
    print("\n" + "="*50)
    print("TEST 5: Simple Functional Test")
    print("="*50)
    try:
        simple_rag = create_rag_pipeline(documents=sample_docs, retriever_type="bm25")
        result = simple_rag.query("Python c√≥ g√¨ hay?", return_documents=True)
        
        print(f"\nüìã Question: {result['question']}")
        if 'error' not in result:
            print(f"üí° Answer: {result['answer']}")
            print(f"üìÑ Documents used: {result['num_documents_used']}")
            
            if result.get('documents'):
                print("\nüìë Retrieved documents:")
                for i, doc in enumerate(result['documents'], 1):
                    print(f"   {i}. {doc['content'][:50]}...")
        else:
            print(f"‚ùå Error: {result['error']}")
        
    except Exception as e:
        print(f"‚ùå Simple test failed: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n‚úÖ RAG Pipeline testing completed!")
